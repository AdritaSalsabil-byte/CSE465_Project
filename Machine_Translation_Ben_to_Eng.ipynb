{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Machine_Translation_Ben_to_Eng.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt",
        "colab_type": "text"
      },
      "source": [
        "# Neural machine translation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g",
        "colab_type": "text"
      },
      "source": [
        "This notebook trains a sequence to sequence (seq2seq) model for Bangla to English translation. \n",
        "\n",
        "After training the model in this notebook, you will be able to input a Bengali sentence, such as *\"আমরা জিতে গেছে।\"*, and return the English translation: *\"We won.\"*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxXKDjq3jEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfodePkj3jEa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "There are a variety of languages available, but we'll use the Bengali-English dataset. For convenience, we've hosted a copy of this dataset on Google drive, but you can also download your own copy. After downloading the dataset, here are the steps we'll take to prepare the data:\n",
        "\n",
        "1. Add a *start* and *end* token to each sentence.\n",
        "2. Clean the sentences by removing special characters.\n",
        "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "4. Pad each sentence to a maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIlo1fucWHk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70f9fb79-53fb-4167-e00b-8c75f208d1f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dGt4X7DWY5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27f6c0cc-b0e6-4243-b397-d8e699d6afbf"
      },
      "source": [
        "cd /content/drive/My Drive/Datasets/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GkHxI-1Wgc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40f96fe2-3a17-4369-ee8e-3f82d60b1c3b"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ben.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRVATYOgJs1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Download the file\n",
        "# path_to_zip = tf.keras.utils.get_file(\n",
        "#     'spa-eng.zip', origin='https://drive.google.com/file/d/19BFPbWRl5XY7Xh4te9NjmwcxpUcqjaNU/view?usp=sharing',\n",
        "#     extract=True)\n",
        "\n",
        "# path_to_file = os.path.dirname(path_to_zip)+\"/ben-eng/ben.txt\"\n",
        "corpus_name = \"ben\"\n",
        "corpus = os.path.join(\"/content/drive/My Drive/Datasets/\", corpus_name)\n",
        "\n",
        "path_to_file = os.path.join(corpus, \"ben.txt\")\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNRl3MMqX-1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "37000ba5-6ea1-422f-a6b8-d4098cc35a23"
      },
      "source": [
        "def printLines(file, n=10):\n",
        "    with open(file, 'r', encoding='utf-8') as path_to_file:\n",
        "        lines = path_to_file.readlines()\n",
        "    for line in lines[:n]:\n",
        "        print(line)\n",
        "        \n",
        "printLines(path_to_file)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tযাও।\n",
            "\n",
            "Go.\tযান।\n",
            "\n",
            "Go.\tযা।\n",
            "\n",
            "Run!\tপালাও!\n",
            "\n",
            "Run!\tপালান!\n",
            "\n",
            "Who?\tকে?\n",
            "\n",
            "Fire!\tআগুন!\n",
            "\n",
            "Help!\tবাঁচাও!\n",
            "\n",
            "Help!\tবাঁচান!\n",
            "\n",
            "Stop!\tথামুন!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd0jw-eC3jEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(string, accents=('COMBINING ACUTE ACCENT', 'COMBINING GRAVE ACCENT', 'COMBINING TILDE')):\n",
        "    accents = set(map(unicodedata.lookup, accents))\n",
        "    chars = [c for c in unicodedata.normalize('NFD', string) if c not in accents]\n",
        "    return unicodedata.normalize('NFC', ''.join(chars))\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([.!?])\", r\" \\1\", w)\n",
        "  w = re.sub(r\"\\s\", r\" \", w).strip()\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  # w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  # w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opI2GzOt479E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4baac285-1497-4359-a2af-4ee8dcb7abae"
      },
      "source": [
        "bn_sentence = u\"আমি চেষ্টা করেছিলাম।\"\n",
        "en_sentence = u\"I tried.\"\n",
        "print(preprocess_sentence(sp_sentence))\n",
        "print(preprocess_sentence(en_sentence))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> আমি চেষ্টা করেছিলাম। <end>\n",
            "<start> i tried . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHn4Dct23jEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTbSbBz55QtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2e451385-d68e-45dd-9a41-27d364aa273c"
      },
      "source": [
        "bn, en = create_dataset(path_to_file, None)\n",
        "print(bn[-1])\n",
        "print(en[-1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> \"i thought doing this would be easy, but we've been working all day and we're still not finished .\" <end>\n",
            "<start> \"আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সারাদিন ধরে কাজ করেছি আর এখনো শেষ করে উঠতে পারিনি।\" <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIOn8RCNDJXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAY9k49G3jE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOi42V79Ydlr",
        "colab_type": "text"
      },
      "source": [
        "### Limit the size of the dataset to experiment faster \n",
        "\n",
        "Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnxC7q-j3jFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QILQkOs3jFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "457afa56-9111-4338-e138-3491cb84a564"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3473 3473 869 869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPmLZGMeD5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXukARTDd7MT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "7409d022-06ee-4167-fe74-25be3057f38d"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> আমি\n",
            "141 ----> ওনাকে\n",
            "131 ----> আজ\n",
            "81 ----> ফোন\n",
            "20 ----> করতে\n",
            "109 ----> ভুলে\n",
            "117 ----> গেছি।\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "5 ----> i\n",
            "339 ----> forgot\n",
            "8 ----> to\n",
            "1074 ----> telephone\n",
            "60 ----> him\n",
            "168 ----> today\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d",
        "colab_type": "text"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqHsArVZ3jFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "910bb9c1-ca86-42fe-8b02-8d4d66958678"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 20]), TensorShape([64, 22]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu",
        "colab_type": "text"
      },
      "source": [
        "## Write the encoder and decoder model\n",
        "\n",
        "Implement an encoder-decoder model \n",
        "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
        "\n",
        "Here are the equations that are implemented:\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "\n",
        "\n",
        "* FC = Fully connected (dense) layer\n",
        "* EO = Encoder output\n",
        "* H = hidden state\n",
        "* X = input to the decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ2rI24i3jFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gSVh05Jl6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8d10aa81-8870-4a47-a2cd-f9dc86d97451"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umohpBN2OM94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k534zTHiDjQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0476e128-02fd-464d-bb77-8b1a1fb246ff"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ_B3mhW3jFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UY8wko3jFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5218353d-7356-4d0a-91c2-369802af0c2f"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 2006)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK",
        "colab_type": "text"
      },
      "source": [
        "## Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTHr5iV3jFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMVWzzsfNl4e",
        "colab_type": "text"
      },
      "source": [
        "## Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8bXQTgNwrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpObfY22IddU",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
        "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
        "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
        "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "5. Use *teacher forcing* to decide the next input to the decoder.\n",
        "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
        "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9ArXSsVfqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddefjBMa3jF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "af1e975f-1775-4c2d-efc4-ff8a85226ef1"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1329\n",
            "Epoch 1 Loss 1.5372\n",
            "Time taken for 1 epoch 26.434791088104248 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.3053\n",
            "Epoch 2 Loss 1.2498\n",
            "Time taken for 1 epoch 6.481097459793091 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1878\n",
            "Epoch 3 Loss 1.1240\n",
            "Time taken for 1 epoch 5.828788995742798 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.0105\n",
            "Epoch 4 Loss 1.0144\n",
            "Time taken for 1 epoch 6.441138505935669 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.9302\n",
            "Epoch 5 Loss 0.9114\n",
            "Time taken for 1 epoch 5.809215068817139 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.9048\n",
            "Epoch 6 Loss 0.8286\n",
            "Time taken for 1 epoch 6.8838934898376465 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.7593\n",
            "Epoch 7 Loss 0.7593\n",
            "Time taken for 1 epoch 5.818735599517822 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.7025\n",
            "Epoch 8 Loss 0.6898\n",
            "Time taken for 1 epoch 6.417241811752319 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.5327\n",
            "Epoch 9 Loss 0.6163\n",
            "Time taken for 1 epoch 5.818506240844727 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.5191\n",
            "Epoch 10 Loss 0.5545\n",
            "Time taken for 1 epoch 6.466636896133423 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz",
        "colab_type": "text"
      },
      "source": [
        "## Translate\n",
        "\n",
        "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "* Stop predicting when the model predicts the *end token*.\n",
        "* And store the *attention weights for every time step*.\n",
        "\n",
        "Note: The encoder output is calculated only once for one input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQpyYs13jF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hQWlbN3jGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9zUHzg3jGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n250XbnjOaqP",
        "colab_type": "text"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJpT9D5_OgP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "033a606f-945f-4af7-809d-c200e04a2b4d"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa2e05176d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrAM0FDomq3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63aec3cd-143a-4229-d951-e8070d2faba4"
      },
      "source": [
        "translate(u'সাহায্য করুন')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> সাহায্য করুন <end>\n",
            "Predicted translation: stop screaming . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2488 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2494 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2489 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2479 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2509 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2453 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2480 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2497 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2472 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2488 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2494 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2489 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2479 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2509 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2453 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2480 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2497 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2472 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx2iM36EZQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "outputId": "69d796bd-1486-41eb-a0a1-a5ac527ec2e5"
      },
      "source": [
        "translate(u'কে')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> কে <end>\n",
            "Predicted translation: how could you go home ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2453 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2503 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2453 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2503 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3LLCx3ZE0Ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6faa3b38-bc25-4136-fa3a-43978b63e40c"
      },
      "source": [
        "translate(u'এটা ব্যবহার কর।')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> এটা ব্যবহার কর। <end>\n",
            "Predicted translation: stop screaming . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2447 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2463 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2494 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2476 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2509 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2479 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2489 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2480 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2453 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2447 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2463 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2494 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2476 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2509 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2479 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2489 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2480 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2453 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQVLVqUE1YW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f8ce777-4c3d-4966-9486-9392f7de59ba"
      },
      "source": [
        "# wrong translation\n",
        "translate(u'আমি যাবো।')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> আমি যাবো। <end>\n",
            "Predicted translation: everyone was screaming . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2438 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2478 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2495 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2479 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2494 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2476 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2507 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2438 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2478 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2495 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2479 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2494 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2476 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2507 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}